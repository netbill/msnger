// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.30.0
// source: inbox.sql

package sqlc

import (
	"context"

	"github.com/jackc/pgx/v5/pgtype"
)

const cleanFailedInboxEvents = `-- name: CleanFailedInboxEvents :exec
UPDATE inbox_events
SET
    status = 'pending',
    attempts = 0,
    next_attempt_at = (now() AT TIME ZONE 'UTC')
WHERE status = 'failed'
`

func (q *Queries) CleanFailedInboxEvents(ctx context.Context) error {
	_, err := q.db.Exec(ctx, cleanFailedInboxEvents)
	return err
}

const cleanProcessingInboxEvents = `-- name: CleanProcessingInboxEvents :exec
UPDATE inbox_events
SET
    status = 'pending',
    reserved_by = NULL,
    next_attempt_at = (now() AT TIME ZONE 'UTC')
WHERE status = 'processing'
`

func (q *Queries) CleanProcessingInboxEvents(ctx context.Context) error {
	_, err := q.db.Exec(ctx, cleanProcessingInboxEvents)
	return err
}

const cleanReservedProcessingInboxEvents = `-- name: CleanReservedProcessingInboxEvents :exec
UPDATE inbox_events
SET
    status = 'pending',
    reserved_by = NULL,
    next_attempt_at = (now() AT TIME ZONE 'UTC')
WHERE status = 'processing'
    AND reserved_by = ANY($1::text[])
`

func (q *Queries) CleanReservedProcessingInboxEvents(ctx context.Context, workerIds []string) error {
	_, err := q.db.Exec(ctx, cleanReservedProcessingInboxEvents, workerIds)
	return err
}

const getInboxEventByID = `-- name: GetInboxEventByID :one
SELECT event_id, seq, topic, key, type, version, producer, payload, partition, kafka_offset, reserved_by, status, attempts, next_attempt_at, last_attempt_at, last_error, processed_at, produced_at, created_at
FROM inbox_events
WHERE event_id = $1
`

func (q *Queries) GetInboxEventByID(ctx context.Context, eventID pgtype.UUID) (InboxEvent, error) {
	row := q.db.QueryRow(ctx, getInboxEventByID, eventID)
	var i InboxEvent
	err := row.Scan(
		&i.EventID,
		&i.Seq,
		&i.Topic,
		&i.Key,
		&i.Type,
		&i.Version,
		&i.Producer,
		&i.Payload,
		&i.Partition,
		&i.KafkaOffset,
		&i.ReservedBy,
		&i.Status,
		&i.Attempts,
		&i.NextAttemptAt,
		&i.LastAttemptAt,
		&i.LastError,
		&i.ProcessedAt,
		&i.ProducedAt,
		&i.CreatedAt,
	)
	return i, err
}

const insertInboxEvent = `-- name: InsertInboxEvent :one
INSERT INTO inbox_events (
    event_id,
    topic, key, type, version, producer, payload, partition, kafka_offset,
    status, attempts, next_attempt_at,
    produced_at
) VALUES (
    $1,
    $2,
    $3,
    $4,
    $5,
    $6,
    $7::jsonb,
    $8,
    $9,
    $10,
    $11,
    $12,
    $13
)
ON CONFLICT (event_id) DO NOTHING
RETURNING event_id, seq, topic, key, type, version, producer, payload, partition, kafka_offset, reserved_by, status, attempts, next_attempt_at, last_attempt_at, last_error, processed_at, produced_at, created_at
`

type InsertInboxEventParams struct {
	EventID       pgtype.UUID
	Topic         string
	Key           string
	Type          string
	Version       int32
	Producer      string
	Payload       []byte
	Partition     int32
	KafkaOffset   int64
	Status        InboxEventStatus
	Attempts      int32
	NextAttemptAt pgtype.Timestamptz
	ProducedAt    pgtype.Timestamptz
}

func (q *Queries) InsertInboxEvent(ctx context.Context, arg InsertInboxEventParams) (InboxEvent, error) {
	row := q.db.QueryRow(ctx, insertInboxEvent,
		arg.EventID,
		arg.Topic,
		arg.Key,
		arg.Type,
		arg.Version,
		arg.Producer,
		arg.Payload,
		arg.Partition,
		arg.KafkaOffset,
		arg.Status,
		arg.Attempts,
		arg.NextAttemptAt,
		arg.ProducedAt,
	)
	var i InboxEvent
	err := row.Scan(
		&i.EventID,
		&i.Seq,
		&i.Topic,
		&i.Key,
		&i.Type,
		&i.Version,
		&i.Producer,
		&i.Payload,
		&i.Partition,
		&i.KafkaOffset,
		&i.ReservedBy,
		&i.Status,
		&i.Attempts,
		&i.NextAttemptAt,
		&i.LastAttemptAt,
		&i.LastError,
		&i.ProcessedAt,
		&i.ProducedAt,
		&i.CreatedAt,
	)
	return i, err
}

const markInboxEventAsFailed = `-- name: MarkInboxEventAsFailed :one
UPDATE inbox_events
SET
    status = 'failed',
    attempts = attempts + 1,
    reserved_by = NULL,
    last_attempt_at = (now() AT TIME ZONE 'UTC'),
    last_error = $1
WHERE event_id = ($2::uuid)
    AND status = 'processing'
    AND reserved_by = $3
RETURNING event_id, seq, topic, key, type, version, producer, payload, partition, kafka_offset, reserved_by, status, attempts, next_attempt_at, last_attempt_at, last_error, processed_at, produced_at, created_at
`

type MarkInboxEventAsFailedParams struct {
	LastError pgtype.Text
	EventID   pgtype.UUID
	WorkerID  pgtype.Text
}

func (q *Queries) MarkInboxEventAsFailed(ctx context.Context, arg MarkInboxEventAsFailedParams) (InboxEvent, error) {
	row := q.db.QueryRow(ctx, markInboxEventAsFailed, arg.LastError, arg.EventID, arg.WorkerID)
	var i InboxEvent
	err := row.Scan(
		&i.EventID,
		&i.Seq,
		&i.Topic,
		&i.Key,
		&i.Type,
		&i.Version,
		&i.Producer,
		&i.Payload,
		&i.Partition,
		&i.KafkaOffset,
		&i.ReservedBy,
		&i.Status,
		&i.Attempts,
		&i.NextAttemptAt,
		&i.LastAttemptAt,
		&i.LastError,
		&i.ProcessedAt,
		&i.ProducedAt,
		&i.CreatedAt,
	)
	return i, err
}

const markInboxEventAsPending = `-- name: MarkInboxEventAsPending :one
UPDATE inbox_events
SET
    status = 'pending',
    attempts = attempts + 1,
    reserved_by = NULL,
    last_attempt_at = (now() AT TIME ZONE 'UTC'),
    next_attempt_at = ($1::timestamptz),
    last_error = $2
WHERE event_id = ($3::uuid)
    AND status = 'processing'
    AND reserved_by = $4
RETURNING event_id, seq, topic, key, type, version, producer, payload, partition, kafka_offset, reserved_by, status, attempts, next_attempt_at, last_attempt_at, last_error, processed_at, produced_at, created_at
`

type MarkInboxEventAsPendingParams struct {
	NextAttemptAt pgtype.Timestamptz
	LastError     pgtype.Text
	EventID       pgtype.UUID
	WorkerID      pgtype.Text
}

func (q *Queries) MarkInboxEventAsPending(ctx context.Context, arg MarkInboxEventAsPendingParams) (InboxEvent, error) {
	row := q.db.QueryRow(ctx, markInboxEventAsPending,
		arg.NextAttemptAt,
		arg.LastError,
		arg.EventID,
		arg.WorkerID,
	)
	var i InboxEvent
	err := row.Scan(
		&i.EventID,
		&i.Seq,
		&i.Topic,
		&i.Key,
		&i.Type,
		&i.Version,
		&i.Producer,
		&i.Payload,
		&i.Partition,
		&i.KafkaOffset,
		&i.ReservedBy,
		&i.Status,
		&i.Attempts,
		&i.NextAttemptAt,
		&i.LastAttemptAt,
		&i.LastError,
		&i.ProcessedAt,
		&i.ProducedAt,
		&i.CreatedAt,
	)
	return i, err
}

const markInboxEventAsProcessed = `-- name: MarkInboxEventAsProcessed :one
UPDATE inbox_events
SET
    status = 'processed',
    attempts = attempts + 1,
    reserved_by = NULL,
    last_attempt_at = (now() AT TIME ZONE 'UTC'),
    processed_at = (now() AT TIME ZONE 'UTC'),
    last_error = NULL
WHERE event_id = ($1::uuid)
    AND status = 'processing'
    AND reserved_by = $2
RETURNING event_id, seq, topic, key, type, version, producer, payload, partition, kafka_offset, reserved_by, status, attempts, next_attempt_at, last_attempt_at, last_error, processed_at, produced_at, created_at
`

type MarkInboxEventAsProcessedParams struct {
	EventID  pgtype.UUID
	WorkerID pgtype.Text
}

func (q *Queries) MarkInboxEventAsProcessed(ctx context.Context, arg MarkInboxEventAsProcessedParams) (InboxEvent, error) {
	row := q.db.QueryRow(ctx, markInboxEventAsProcessed, arg.EventID, arg.WorkerID)
	var i InboxEvent
	err := row.Scan(
		&i.EventID,
		&i.Seq,
		&i.Topic,
		&i.Key,
		&i.Type,
		&i.Version,
		&i.Producer,
		&i.Payload,
		&i.Partition,
		&i.KafkaOffset,
		&i.ReservedBy,
		&i.Status,
		&i.Attempts,
		&i.NextAttemptAt,
		&i.LastAttemptAt,
		&i.LastError,
		&i.ProcessedAt,
		&i.ProducedAt,
		&i.CreatedAt,
	)
	return i, err
}

const reserveInboxEvents = `-- name: ReserveInboxEvents :many
WITH ready AS (
    SELECT event_id, seq, topic, key, type, version, producer, payload, partition, kafka_offset, reserved_by, status, attempts, next_attempt_at, last_attempt_at, last_error, processed_at, produced_at, created_at
    FROM inbox_events
    WHERE status = 'pending'
        AND reserved_by IS NULL
        AND next_attempt_at <= (now() AT TIME ZONE 'UTC')
    ORDER BY produced_at, partition, kafka_offset
    FOR UPDATE SKIP LOCKED
    LIMIT $2
),
key_heads AS (
    -- головы только внутри ограниченного ready-набора
    SELECT DISTINCT ON (r.topic, r.key)
        r.topic,
        r.key,
        r.produced_at AS head_produced_at
    FROM ready r
    -- не берём key, который уже processing (проверка по основной таблице быстрая через индекс processing_key_idx)
    WHERE NOT EXISTS (
        SELECT 1
        FROM inbox_events p
        WHERE p.topic = r.topic
            AND p.key = r.key
            AND p.status = 'processing'
            AND p.reserved_by IS NOT NULL
    )
    ORDER BY r.topic, r.key, r.produced_at
),
picked AS (
    -- теперь выбираем события ТОЛЬКО по выбранным key
    SELECT e.event_id
    FROM inbox_events e
    JOIN key_heads k ON k.topic = e.topic AND k.key = e.key
    WHERE e.status = 'pending'
        AND e.reserved_by IS NULL
        AND e.next_attempt_at <= (now() AT TIME ZONE 'UTC')
    ORDER BY k.head_produced_at, e.produced_at, e.kafka_offset
    FOR UPDATE SKIP LOCKED
    LIMIT $3
)
UPDATE inbox_events e
SET reserved_by = $1,
    status      = 'processing'
WHERE e.event_id IN (SELECT event_id FROM picked)
RETURNING event_id, seq, topic, key, type, version, producer, payload, partition, kafka_offset, reserved_by, status, attempts, next_attempt_at, last_attempt_at, last_error, processed_at, produced_at, created_at
`

type ReserveInboxEventsParams struct {
	WorkerID   pgtype.Text
	SortLimit  int32
	BatchLimit int32
}

func (q *Queries) ReserveInboxEvents(ctx context.Context, arg ReserveInboxEventsParams) ([]InboxEvent, error) {
	rows, err := q.db.Query(ctx, reserveInboxEvents, arg.WorkerID, arg.SortLimit, arg.BatchLimit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []InboxEvent
	for rows.Next() {
		var i InboxEvent
		if err := rows.Scan(
			&i.EventID,
			&i.Seq,
			&i.Topic,
			&i.Key,
			&i.Type,
			&i.Version,
			&i.Producer,
			&i.Payload,
			&i.Partition,
			&i.KafkaOffset,
			&i.ReservedBy,
			&i.Status,
			&i.Attempts,
			&i.NextAttemptAt,
			&i.LastAttemptAt,
			&i.LastError,
			&i.ProcessedAt,
			&i.ProducedAt,
			&i.CreatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}
